---
title: ''
output: html_document
---

# Import data

```{r, message=F, warning=F}
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyr)
library(dplyr)
library(qdap)
library(stringr)
library(knitr)

setwd("~/Repos/reference_games/analysis")

msgs = read.csv("../data/colorReference/message/colorReferenceMessage.csv") %>%
  rename(msgTime = time, 
         role = sender)

clks = read.csv("../data/colorReference/clickedObj/extendedColorReferenceClicks.csv") %>%
  mutate(condition = factor(condition, levels = c("closer", "further", "equal"), labels = c("hard", "medium", "easy"))) %>%
  rename(clkTime = time)

subjInfo = read.csv("../data/colorReference/turk/colorReference-subject_information.csv") %>%
  rename(gameid = gameID) %>%
  select(-workerid)

mean(subjInfo$totalLength / 1000 / 60)
```

# Pre-processing

There's a bunch of additional pre-processing that it's still be nice to do. For instance, it would be nice to strip all the meta-commentary (e.g. "oops" after missing, complaining about task, etc.), exclude confused people & non-native english speakers.

```{r}
# For later bar plots
dodge <- position_dodge(width=0.9)

rawAggregated <- clks %>% 
  left_join(msgs, by = c("gameid", "roundNum")) %>%
  left_join(subjInfo, by = c("gameid", "role")) 

goodGames <- unique((rawAggregated %>% 
  filter(nativeEnglish == "yes") %>%
  filter(confused == "yes") %>%
  group_by(gameid) %>%
  filter(length(unique(roundNum)) == 50))$gameid)

combined <- rawAggregated %>%
  filter(gameid %in% goodGames) %>%
  mutate(numOutcome = ifelse(outcome == "true", 1, 0)) %>%
  mutate(numRawWords = 1 + str_count(contents, fixed(" "))) %>%
  mutate(strippedContents = str_replace_all(contents, "[^[:alnum:][:space:]']",' ')) %>%
  do(mutate(., cleanMsg = rm_stopwords(.$strippedContents, tm::stopwords("english"), 
                                       separate = F))) %>%
  mutate(numCleanChars = nchar(as.character(cleanMsg))) %>%
  mutate(numCleanWords = 1 + str_count(cleanMsg, fixed(" "))) %>%
  filter(numCleanWords < mean(numCleanWords) + 3*sd(numCleanWords))
```

# Analysis: How often to listeners talk back?

We're mostly interested in the words that speakers choose to describe colors, but listeners say things, too. For instance, they may ask clarification questions on particularly difficult questions, evoking longer answers. Can we safely exclude listeners from our later analyses for simplicity? Are listeners more likely to peep up on harder trials?

```{r}
ggplot(combined %>% 
         group_by(gameid, role, condition) %>% 
         tally() %>% 
         ungroup() %>% 
         complete(gameid,condition,role, fill = list(n = 0)) %>% # fill 0s for listeners
         group_by(role, condition) %>% 
         summarize(numMessagesSent = mean(n), se = sd(n)/sqrt(length(n))), 
       aes(x = condition, y = numMessagesSent, fill = role)) +
  geom_bar(stat = "identity", position = dodge) +
  geom_errorbar(aes(ymax = numMessagesSent + se, ymin = numMessagesSent - se), 
                    position=dodge, width=0.25) +
  ggtitle("How often do listeners talk back?")
```

So listeners talk more on harder trials, but always *much* less than speakers (an average of 4 messages per game combined to 50 messages by speakers)

We might expect that they'd ask questions more than speakers... Let's count question marks... 

```{r}
ggplot(combined %>% 
         group_by(gameid, role,condition) %>%
         summarise(n = str_count(paste(contents, collapse=" "), fixed("?"))) %>%
         ungroup() %>% 
         complete(gameid,condition,role, fill = list(n = 0)) %>% 
         group_by(role, condition) %>% 
         summarize(numQuestionsAsked = mean(n), se = sd(n)/sqrt(length(n))), 
       aes(x = condition, y = numQuestionsAsked, fill = role)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymax = numQuestionsAsked + se, ymin = numQuestionsAsked - se), 
                  position=dodge, width=0.25) +
  ggtitle("how many questions did each player ask?")
```

Yep! Speakers actually use questions, too, to mark uncertainty (e.g. "purple?"), and it actually looks like the number of questions falls off with the difficulty of the trial. Note that a lot of these are meta-questions like "are you there?" or "Are you a robot?" Might want to scrub these later.

# Analysis: Most common words?

```{r}
speakerWords <- combined %>%
  filter(role == "speaker") %>%
  summarize(wordList = paste(cleanMsg, collapse = " "))
sort(table(strsplit(speakerWords$wordList, ' ')), decreasing=T)[1:75]
```

# Analysis: Do people use more *words* on harder trials?

```{r}
summary(lmer(n ~ condition + (1 | gameid),
     data = combined %>% group_by(gameid, condition) %>% summarise(n = sum(numCleanWords))))

ggplot(combined %>% 
         filter(role == "speaker") %>%
         group_by(gameid, condition) %>%
         summarise(n = sum(numCleanWords)/length(numCleanWords)) %>%
         group_by(condition) %>% 
         summarize(numWordsUsed = mean(n), se = sd(n)/sqrt(length(n))), 
       aes(x = condition, y = numWordsUsed)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymax = numWordsUsed + se, ymin = numWordsUsed - se), 
                  position=dodge, width=0.25) +
  ylab("Average # words per message")+
  theme_bw() +
  ggtitle("Average words by context")
```

Instead of grouping them into these big bins, why not use the continuous similarity metric?

```{r}
similarityD = combined %>% 
   group_by(gameid, roundNum) %>% 
   filter(role == "speaker") %>%
   filter(row_number()==1) %>%
   mutate(numWords = numCleanWords,
         totalSimilarity = targetD1Diff + targetD2Diff,
         meanSimilarity = mean(targetD1Diff, targetD2Diff),
         minSimilarity = min(targetD1Diff, targetD2Diff))

summary(lmer(numWords ~ totalSimilarity + (1 | gameid), data = similarityD))

ggplot(similarityD %>% filter(totalSimilarity < 190), 
       aes(x = totalSimilarity, y = numWords)) +
  geom_smooth(method = loess, size = 2) + 
  geom_point(alpha = 0.1, position = position_jitter(w = 0.5, h = 0.5)) +
  ylim(0,6) +
  ylab("# words used") +
  theme_bw() +
  ggtitle("Do speakers use more words on harder trials?")

ggplot(similarityD %>% 
         mutate(similarityBin = cut(totalSimilarity, seq(5, 150, 1), labels = FALSE)) %>%
         group_by(similarityBin) %>% 
         summarize(numWordsUsed = mean(numWords), se = sd(numWords)/sqrt(length(numWords))) %>%
         filter(similarityBin < 150), 
       aes(x = similarityBin, y = numWordsUsed)) +
  geom_smooth(method = loess, size = 2) + 
  geom_point() +
  geom_errorbar(aes(ymax = numWordsUsed + 2*se, ymin = numWordsUsed - 2*se)) +
  ylim(0,4) +
  ylab("# words used (mean)") +
  theme_bw()
```

# Analysis: Do people make more mistakes on harder trials:

```{r}
conditionMod = glmer(numOutcome ~ condition + (1 | gameid), family = "binomial", 
      data = combined %>% 
        group_by(gameid, roundNum) %>% 
        filter(row_number()==1) %>%
        filter(role == "speaker"))
summary(conditionMod)

ggplot(combined %>% group_by(gameid, roundNum) %>% filter(row_number()==1) %>%
         filter(role == "speaker") %>% group_by(condition) %>%
         summarize(percentCorrect = mean(numOutcome), 
                   se = sqrt(percentCorrect*(1 - percentCorrect)
                             /length(numOutcome))),
  aes(x = condition, y = percentCorrect)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymax = percentCorrect + se, ymin = percentCorrect - se), 
                position=dodge, width=0.25) + 
  theme_bw()

```

# Analysis: Does using more words predict correct responses?

```{r}
numWordsMod = glmer(numOutcome ~ numCleanWords + condition + (1 | gameid), 
                  family = "binomial",
                  data = combined %>% group_by(gameid, roundNum) %>%
                    filter(row_number() == 1) %>% filter(role == "speaker"))
summary(numWordsMod)
anova(conditionMod, numWordsMod)

ggplot(combined %>% group_by(gameid, roundNum) %>% filter(row_number()==1) %>%
         filter(role == "speaker") %>%
         mutate(numOutcome = ifelse(outcome == "true", 1, 0)) %>% ungroup() %>%
         do(mutate(., predicted = predict(fittedProbs, ., type = "response"))),
       aes(x = numCleanWords, y = numOutcome, color = condition)) +
  geom_point(alpha = 0.1, position = position_jitter(w = 0.5, h = 0)) +
  geom_line(aes(y = predicted))
```

Not after controlling for difficulty... 

# Analysis: Exclusionary words like "not"

Do they even use it? 

```{r}
ggplot(combined %>% 
         group_by(gameid, role,condition) %>%
         summarise(n = str_count(paste(contents, collapse=" "), fixed("not"))) %>%
         ungroup() %>% 
         complete(gameid,condition,role, fill = list(n = 0)) %>% 
         group_by(role, condition) %>% 
         summarize(numNotsUsed = mean(n), se = sd(n)/sqrt(length(n))), 
       aes(x = condition, y = numNotsUsed, fill = role)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymax = numNotsUsed + se, ymin = numNotsUsed - se), 
                  position=dodge, width=0.25)
```

# Analysis: How does behavior change over time?

```{r}
ggplot(combined %>% 
    group_by(roundNum, gameid) %>% 
    filter(row_number()==1) %>%
    filter(role == "speaker") %>%
  summarize(meanNumWords = mean(numRawWords)),
  aes(x = roundNum, y = meanNumWords)) +
  geom_line() +
  facet_wrap(~ gameid)
```

Doesn't look like very many people have a trend over time

```{r}
colorConvMod = lmer(numCleanChars ~ condition + roundNum + (1 + condition| gameid), 
     data = combined %>% 
  group_by(gameid, roundNum) %>%
  filter(row_number()==1) %>%
  filter(role == "speaker"))

summary(colorConvMod)
pdf("colorReferenceFigs/colorConv.pdf")
ggplot(combined %>% 
  group_by(gameid, roundNum) %>%
  filter(row_number()==1) %>%
  filter(role == "speaker") %>%
  group_by(roundNum, condition) %>% 
  summarize(meanNumWords = mean(numCleanWords)),
  aes(x = roundNum, y = meanNumWords, color = condition)) +
  geom_point() +
  geom_smooth() +
  ggtitle("Do people conventionalize?") +
  theme_bw()
dev.off()
```

If there is an effect, averaging across people, it looks like it might be limited to the equal condition (i.e. people start to recognize that on easy trials they only need a word or two)

# Colors: Do different participants carve up the space differently?

```{r}
# ggplot(combined %>% filter(gameid == "9960-e"), 
#        aes(x = targetX, y = targetY, colour = targetHex,label = cleanMsg)) +
#   geom_text()+
#   scale_colour_identity() +
#   theme_bw() 

colors <- read.csv("../data/colorReference/clickedObj/colorMap.csv")
ggplot(combined %>% filter(gameid == "9960-e"), 
       aes(x = targetX, y = targetY)) +
  geom_point(data = colors, aes(x = x, y = y, colour = hex, size = 20), 
             show_guide = FALSE) +
  geom_text(aes(label = cleanMsg, color = "white")) +
  scale_colour_identity() +
  theme_bw()

```

# Generate latex table for TACL paper:

Want to make a table with the different conditions as columns and different metrics as rows... 

```{r}
# TODO: use stanford pos tagger
taggedDF = read.csv("color/taggedColorMsgs.csv")

# TODO: present se in table (e.g. in parens after mean)
resultTable = combined %>% 
  left_join(taggedDF, by = c("gameid", "roundNum", "contents")) %>%
   filter(role == "speaker") %>%
   group_by(gameid, condition) %>%
   summarise(numWordsPerMessage = sum(numCleanWords)/length(numCleanWords),
             numCharsPerMessage = sum(numCleanChars)/length(numCleanChars),
             numComparatives = sum(numComp)/length(numComp),
             numSuperlatives = sum(numSuper)/length(numSuper),
             numNegatives = str_count(paste(contents, collapse=" "),
                                      fixed("not"))/length(numCleanWords),
             levelOfRef = NA) %>%
  mutate(condition = ordered(condition, levels = c("easy", "medium", "hard"),
                               labels = c("far", "split", "close"))) %>%
   group_by(condition) %>% 
   summarize("# WordsM" = mean(numWordsPerMessage), 
             "# CharsM" = mean(numCharsPerMessage),
             numWordsPerMessageSE = sd(numWordsPerMessage)/sqrt(length(numWordsPerMessage)),
             "# NegativesM" = mean(numNegatives),
             numNegativesSE = sd(numNegatives)/sqrt(length(numNegatives)),
             "# ComparativesM" = mean(numComparatives),
             "# SuperlativesM" = mean(numSuperlatives)) %>%
  gather(metric, mu, ends_with("M")) %>%
  #gather(garbage, se, ends_with("SE")) %>%
  mutate("metric (per message)" = gsub(".$", "", metric)) %>%
  select(-ends_with("SE"), -metric) %>%
  spread(condition, mu)

print(xtable(resultTable, label = "table:metrics"), include.rownames = FALSE)
```
